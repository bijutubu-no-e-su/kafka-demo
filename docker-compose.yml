services:
  # --- このファイルは docker compose で各サービスをまとめて起動する定義です ---
  # サービス名は compose ネットワーク内の DNS 名（例: kafka, pg, connect, ksqldb, ui）になります。
  # 各サービスは内部ホスト名で相互に通信する想定です（例: connect -> pg, connect -> kafka）。
  kafka:
    image: confluentinc/cp-kafka:7.6.1
    platform: linux/amd64
    container_name: kafka
    ports:
      - '29092:29092' # ホスト→localhost:29092
    environment:
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_NODE_ID: 1
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka:29093'
      KAFKA_LISTENERS: 'PLAINTEXT://kafka:9092,CONTROLLER://kafka:29093,PLAINTEXT_HOST://0.0.0.0:29092'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092'
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT,CONTROLLER:PLAINTEXT'
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_LOG_DIRS: /var/lib/kafka/data
    volumes:
      - kafkadata:/var/lib/kafka/data
    command: >
      bash -lc '
        set -e

        # 1) CLUSTER_ID を用意（未設定なら生成）
        if [ -z "$${CLUSTER_ID:-}" ]; then
          if command -v kafka-storage >/dev/null 2>&1; then
            export CLUSTER_ID=$$(kafka-storage random-uuid)
          else
            export CLUSTER_ID=$$(kafka-storage.sh random-uuid)
          fi
          echo "[kafka] generated CLUSTER_ID=$$CLUSTER_ID"
        else
          echo "[kafka] using provided CLUSTER_ID=$$CLUSTER_ID"
        fi

        # 2) env→/etc/kafka/kafka.properties 生成
        /etc/confluent/docker/configure

        # 3) 初回のみフォーマット
        if [ ! -f "/var/lib/kafka/data/meta.properties" ]; then
          echo "[kafka] formatting storage with CLUSTER_ID=$$CLUSTER_ID..."
          if command -v kafka-storage >/dev/null 2>&1; then
            kafka-storage format --ignore-formatted -t "$$CLUSTER_ID" -c /etc/kafka/kafka.properties
          else
            kafka-storage.sh format --ignore-formatted -t "$$CLUSTER_ID" -c /etc/kafka/kafka.properties
          fi
        fi

        # 4) 通常起動
        exec /etc/confluent/docker/run
      '
    healthcheck:
      test:
        [
          'CMD',
          'bash',
          '-lc',
          'kafka-topics --bootstrap-server kafka:9092 --list >/dev/null 2>&1 || exit 1',
        ]
      interval: 10s
      timeout: 5s
      retries: 30
  postgres:
    # Debezium が推奨する Postgres 連携イメージ。logical replication に必要な設定が含まれる
    image: debezium/postgres:16-alpine
    container_name: pg
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=demo
    ports:
      - '5432:5432'
    volumes:
      # 起動時に init スクリプトを実行してスキーマ/サンプルデータを投入
      - ./init:/docker-entrypoint-initdb.d:ro
    healthcheck:
      test: ['CMD-SHELL', 'pg_isready -U postgres -d demo']
      interval: 5s
      timeout: 5s
      retries: 30
  connect:
    # Debezium Connect: Postgres の変更を Kafka に送るコネクタを動かす
    # connector の登録は REST API（http://connect:8083）に対して行う
    image: debezium/connect:2.6
    platform: linux/amd64
    container_name: connect
    depends_on:
      kafka:
        condition: service_healthy
      postgres:
        condition: service_started
    ports:
      - '8083:8083'
    environment:
      BOOTSTRAP_SERVERS: kafka:9092
      GROUP_ID: connect-cluster
      CONFIG_STORAGE_TOPIC: _connect_configs
      OFFSET_STORAGE_TOPIC: _connect_offsets
      STATUS_STORAGE_TOPIC: _connect_status
      KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      KEY_CONVERTER_SCHEMAS_ENABLE: 'false'
      VALUE_CONVERTER_SCHEMAS_ENABLE: 'false'
    healthcheck:
      test: ['CMD', 'curl', '-fsS', 'http://localhost:8083/connectors']
      interval: 10s
      timeout: 5s
      retries: 30
    command:
      - bash
      - -lc
      - |
        /docker-entrypoint.sh start
  ksqldb:
    # ksqlDB サーバー: Kafka のストリームを SQL ライクに処理できる
    image: confluentinc/ksqldb-server:0.29.0
    platform: linux/amd64
    container_name: ksqldb
    depends_on:
      kafka:
        condition: service_healthy
    ports:
      - '8088:8088'
    environment:
      KSQL_BOOTSTRAP_SERVERS: kafka:9092
      KSQL_LISTENERS: http://0.0.0.0:8088
      KSQL_KSQL_SERVICE_ID: 'ksql-demo'
      KSQL_KSQL_STREAMS_AUTO_OFFSET_RESET: earliest
    volumes:
      - ./ksql/statements.sql:/etc/ksqldb/statements.sql:ro
  # Debezium コネクタ登録（ワンショット）
  connect-init:
    image: curlimages/curl:8.8.0
    container_name: connect-init
    depends_on:
      connect:
        condition: service_healthy
      postgres:
        condition: service_healthy
    entrypoint: ['/bin/sh', '-c', '/work/register.sh']
    volumes:
      - ./connect-init/register.sh:/work/register.sh:ro

  # DB書き戻し（B/C/Dトピック → Postgres upsert）
  db-writer:
    build: ./db-writer
    platform: linux/amd64
    container_name: db-writer
    depends_on:
      kafka:
        condition: service_healthy
      postgres:
        condition: service_healthy
    environment:
      KAFKA_BROKER: kafka:9092
      TOPICS: b_panel_topic,c_panel_topic,d_panel_topic
      PGHOST: pg
      PGPORT: '5432'
      PGDATABASE: demo
      PGUSER: postgres
      PGPASSWORD: postgres
  ui:
    # シンプルな React + Express の UI。kafkajs でトピックを購読し SSE でブラウザへ配信する
    build: ./ui
    container_name: ui
    platform: linux/amd64
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      KAFKA_BROKER: kafka:9092
      KAFKA_GROUP_ID: ui-sse-group
      TOPICS: pg.public.a_panel,b_panel_topic,c_panel_topic,d_panel_topic
      # TOPICS: pg.public.a_panel,B_STREAM,C_STREAM,D_STREAM
      PORT: 3000
    ports:
      - '3000:3000'
volumes:
  kafkadata:
